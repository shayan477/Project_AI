{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 151619,
     "status": "ok",
     "timestamp": 1747770960110,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "GotseZMmJMQm",
    "outputId": "ea751051-1a4d-4534-e08d-4bccd2f7b758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!unzip -q /content/drive/MyDrive/archive.zip -d /content/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 427213,
     "status": "ok",
     "timestamp": 1747771387314,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "MI2BBSsEJX9l",
    "outputId": "6c115852-2e78-40c0-b4c8-bd403e77a03c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames extracted.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "input_root = '/content/Real Life Violence Dataset'\n",
    "output_root = '/content/Images'\n",
    "\n",
    "label_map = {\n",
    "    'Violence': 'fighting',\n",
    "    'NonViolence': 'non-fighting'\n",
    "}\n",
    "\n",
    "frame_rate = 1  # Extract 1 frame per second\n",
    "\n",
    "for original_label, new_label in label_map.items():\n",
    "    input_folder = os.path.join(input_root, original_label)\n",
    "    output_folder = os.path.join(output_root, new_label)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for video_name in os.listdir(input_folder):\n",
    "        if not video_name.lower().endswith('.mp4'):\n",
    "            continue\n",
    "\n",
    "        video_path = os.path.join(input_folder, video_name)\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        count = 0\n",
    "        frame_id = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if count % max(1, (fps // frame_rate)) == 0:\n",
    "                frame_filename = f\"{video_name[:-4]}_frame{frame_id}.jpg\"\n",
    "                frame_path = os.path.join(output_folder, frame_filename)\n",
    "                cv2.imwrite(frame_path, frame)\n",
    "                frame_id += 1\n",
    "            count += 1\n",
    "        cap.release()\n",
    "\n",
    "print(\"Frames extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5945,
     "status": "ok",
     "timestamp": 1747773707451,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "BzVvpgAlVylx",
    "outputId": "94edb971-4abc-4ac0-c46a-7cebbf34e7b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying fighting → train: 100%|██████████| 4082/4082 [00:04<00:00, 947.95it/s]\n",
      "Copying fighting → val: 100%|██████████| 874/874 [00:00<00:00, 4343.57it/s]\n",
      "Copying fighting → test: 100%|██████████| 876/876 [00:00<00:00, 4396.39it/s]\n",
      "Copying non-fighting → train: 100%|██████████| 3489/3489 [00:00<00:00, 3768.38it/s]\n",
      "Copying non-fighting → val: 100%|██████████| 747/747 [00:00<00:00, 6080.90it/s]\n",
      "Copying non-fighting → test: 100%|██████████| 749/749 [00:00<00:00, 4825.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Frame dataset split into train/val/test at /content/dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ─── Split extracted frames into train/val/test ───────────────────────────────\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# reproducible splits\n",
    "random.seed(42)\n",
    "\n",
    "input_dir   = '/content/Images'\n",
    "output_base = '/content/dataset'\n",
    "splits      = ['train', 'val', 'test']\n",
    "ratios      = [0.7, 0.15, 0.15]\n",
    "\n",
    "# create output folder structure\n",
    "for split in splits:\n",
    "    for label in os.listdir(input_dir):\n",
    "        os.makedirs(os.path.join(output_base, split, label), exist_ok=True)\n",
    "\n",
    "# perform the actual split\n",
    "for label in os.listdir(input_dir):\n",
    "    all_imgs = os.listdir(os.path.join(input_dir, label))\n",
    "    random.shuffle(all_imgs)\n",
    "\n",
    "    n_total = len(all_imgs)\n",
    "    n_train = int(ratios[0] * n_total)\n",
    "    n_val   = int(ratios[1] * n_total)\n",
    "\n",
    "    split_imgs = {\n",
    "        'train': all_imgs[:n_train],\n",
    "        'val'  : all_imgs[n_train:n_train + n_val],\n",
    "        'test' : all_imgs[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    for split, imgs in split_imgs.items():\n",
    "        for img in tqdm(imgs, desc=f\"Copying {label} → {split}\"):\n",
    "            src = os.path.join(input_dir, label, img)\n",
    "            dst = os.path.join(output_base, split, label, img)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "print(\"✅ Frame dataset split into train/val/test at\", output_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747773730393,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "PQc3Z_NSJvz8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1747773731257,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "k4xgOk7fJ1S9",
    "outputId": "3d6d23cf-dea7-4af7-c0e9-9e7750d48020"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747773732439,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "JILaA9P3J4Kc"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747773733837,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "Q9bBgf5CJ8FW"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747773736049,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "OR_2-x9nJ-Fd"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747773737302,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "vINQQoJqJ_Gu"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "\n",
    "        for idx, class_name in enumerate(self.classes):\n",
    "            class_folder = os.path.join(root_dir, class_name)\n",
    "            for img_file in os.listdir(class_folder):\n",
    "                self.image_paths.append(os.path.join(class_folder, img_file))\n",
    "                self.labels.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1747773739337,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "XKWDFJZjJ_Eu"
   },
   "outputs": [],
   "source": [
    "train_dataset = ImageDataset(\"/content/dataset/train\", transform=transform)\n",
    "val_dataset   = ImageDataset(\"/content/dataset/val\",   transform=transform)\n",
    "test_dataset  = ImageDataset(\"/content/dataset/test\",  transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58,
     "status": "ok",
     "timestamp": 1747773741643,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "04vJjfszJ-8G",
    "outputId": "ccfe4d02-b02a-4fd2-ddec-9fcfaca3270f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10817"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1747773743563,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "sa2CDrnTJ-42"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1747773745002,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "9ZDySberJ-1b"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1747773747000,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "OInqXZinJ-zD",
    "outputId": "80c423a8-3f61-4426-c621-5fc0bab45b13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 224, 224]), torch.Size([32]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape, labels.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1747773749577,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "fyuIqV67J-m1"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        hidden_features = hidden_features or in_features\n",
    "        out_features = out_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1747773750406,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "VQIY94MnKRfp"
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.heads, C // self.heads)\n",
    "        q, k, v = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1747773751351,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "d0rm2s7dKRb_"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = AttentionBlock(dim, heads, dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = MLP(dim, mlp_dim, dropout=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2213,
     "status": "ok",
     "timestamp": 1747773754604,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "OmrSeDiRbcPy",
    "outputId": "a9919e1a-3f55-47bb-a3bf-cec21918c8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 126,
     "status": "ok",
     "timestamp": 1747773754736,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "cVtZlYJ7KRZv",
    "outputId": "af70219c-1098-4a9a-ae02-fd73ad23b16c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ViT                                      [1, 2]                    101,376\n",
       "├─Linear: 1-1                            [1, 196, 512]             393,728\n",
       "├─Dropout: 1-2                           [1, 197, 512]             --\n",
       "├─Sequential: 1-3                        [1, 197, 512]             --\n",
       "│    └─TransformerBlock: 2-1             [1, 197, 512]             --\n",
       "│    │    └─LayerNorm: 3-1               [1, 197, 512]             1,024\n",
       "│    │    └─AttentionBlock: 3-2          [1, 197, 512]             1,050,624\n",
       "│    │    └─LayerNorm: 3-3               [1, 197, 512]             1,024\n",
       "│    │    └─MLP: 3-4                     [1, 197, 512]             1,050,112\n",
       "│    └─TransformerBlock: 2-2             [1, 197, 512]             --\n",
       "│    │    └─LayerNorm: 3-5               [1, 197, 512]             1,024\n",
       "│    │    └─AttentionBlock: 3-6          [1, 197, 512]             1,050,624\n",
       "│    │    └─LayerNorm: 3-7               [1, 197, 512]             1,024\n",
       "│    │    └─MLP: 3-8                     [1, 197, 512]             1,050,112\n",
       "│    └─TransformerBlock: 2-3             [1, 197, 512]             --\n",
       "│    │    └─LayerNorm: 3-9               [1, 197, 512]             1,024\n",
       "│    │    └─AttentionBlock: 3-10         [1, 197, 512]             1,050,624\n",
       "│    │    └─LayerNorm: 3-11              [1, 197, 512]             1,024\n",
       "│    │    └─MLP: 3-12                    [1, 197, 512]             1,050,112\n",
       "│    └─TransformerBlock: 2-4             [1, 197, 512]             --\n",
       "│    │    └─LayerNorm: 3-13              [1, 197, 512]             1,024\n",
       "│    │    └─AttentionBlock: 3-14         [1, 197, 512]             1,050,624\n",
       "│    │    └─LayerNorm: 3-15              [1, 197, 512]             1,024\n",
       "│    │    └─MLP: 3-16                    [1, 197, 512]             1,050,112\n",
       "│    └─TransformerBlock: 2-5             [1, 197, 512]             --\n",
       "│    │    └─LayerNorm: 3-17              [1, 197, 512]             1,024\n",
       "│    │    └─AttentionBlock: 3-18         [1, 197, 512]             1,050,624\n",
       "│    │    └─LayerNorm: 3-19              [1, 197, 512]             1,024\n",
       "│    │    └─MLP: 3-20                    [1, 197, 512]             1,050,112\n",
       "│    └─TransformerBlock: 2-6             [1, 197, 512]             --\n",
       "│    │    └─LayerNorm: 3-21              [1, 197, 512]             1,024\n",
       "│    │    └─AttentionBlock: 3-22         [1, 197, 512]             1,050,624\n",
       "│    │    └─LayerNorm: 3-23              [1, 197, 512]             1,024\n",
       "│    │    └─MLP: 3-24                    [1, 197, 512]             1,050,112\n",
       "├─LayerNorm: 1-4                         [1, 197, 512]             1,024\n",
       "├─Linear: 1-5                            [1, 2]                    1,026\n",
       "==========================================================================================\n",
       "Total params: 13,113,858\n",
       "Trainable params: 13,113,858\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 13.01\n",
       "==========================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 45.18\n",
       "Params size (MB): 52.05\n",
       "Estimated Total Size (MB): 97.84\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate ViT and move to the selected device\n",
    "model = ViT(\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_classes=2,\n",
    "    dim=512,\n",
    "    depth=6,\n",
    "    heads=8,\n",
    "    mlp_dim=1024,\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "# Display a model summary (torchinfo)\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(1, 3, 224, 224),\n",
    "    device=device  # explicitly named to avoid empty() kwargs error\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1747773757850,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "y0HRO9QRKRS0"
   },
   "outputs": [],
   "source": [
    "model = ViT().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1133029,
     "status": "ok",
     "timestamp": 1747774893318,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "hV3kIEmzKRQ4",
    "outputId": "faa7607d-4fcd-4696-8786-228f35a1c5bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 222.4980, Accuracy: 61.56%\n",
      "Epoch 2/10, Loss: 177.3808, Accuracy: 73.00%\n",
      "Epoch 3/10, Loss: 146.7617, Accuracy: 79.35%\n",
      "Epoch 4/10, Loss: 117.3953, Accuracy: 84.33%\n",
      "Epoch 5/10, Loss: 103.6667, Accuracy: 86.93%\n",
      "Epoch 6/10, Loss: 112.1306, Accuracy: 84.96%\n",
      "Epoch 7/10, Loss: 82.1567, Accuracy: 89.77%\n",
      "Epoch 8/10, Loss: 73.4487, Accuracy: 90.77%\n",
      "Epoch 9/10, Loss: 71.7145, Accuracy: 91.14%\n",
      "Epoch 10/10, Loss: 68.1225, Accuracy: 91.80%\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1747774893370,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "pokvoW-kKRE3"
   },
   "outputs": [],
   "source": [
    "# Save model with state_dict and class mapping\n",
    "torch.save({\n",
    "    \"state_dict\": model.state_dict(),\n",
    "    \"idx_to_class\": {0: \"non-fighting\", 1: \"fighting\"}\n",
    "}, \"vit_model4.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12055,
     "status": "ok",
     "timestamp": 1747777532339,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "h2BCnVTQKebF",
    "outputId": "b90642e1-854c-4fc7-cdf9-70586513987e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.97%\n"
     ]
    }
   ],
   "source": [
    "# ─── Evaluate on Test Set ───────────────────────────────────────────────────────\n",
    "model.eval()\n",
    "correct = 0\n",
    "total   = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1747737756419,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "kGPad72FKkIl",
    "outputId": "4c46f3d8-c2d4-4ebf-a152-3c7223333544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0, Actual class: 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 67,
     "status": "error",
     "timestamp": 1747737758173,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "qImB8hXyPUJX",
    "outputId": "f34ba76c-33cd-4c42-93e3-2d8d02d816b6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6eb9638ecbc3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1747775374768,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "uE2MSsT-ScdR",
    "outputId": "6739914e-90a2-4916-fc9c-85c1cd80af23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: -r not specified; omitting directory '/content/dataset'\n"
     ]
    }
   ],
   "source": [
    "!cp /content/dataset /content/drive/MyDrive/AI_Project_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 76019,
     "status": "ok",
     "timestamp": 1747775678175,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "WiM1NyvxS21y"
   },
   "outputs": [],
   "source": [
    "!cp -r /content/dataset /content/drive/MyDrive/AI_Project_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12364,
     "status": "ok",
     "timestamp": 1747777483320,
     "user": {
      "displayName": "Muhammad Shayan Shahid",
      "userId": "17797352603912270040"
     },
     "user_tz": 420
    },
    "id": "AkyinygKivCM",
    "outputId": "89926e78-7de4-4432-e5ec-835109e59377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 93.97%\n"
     ]
    }
   ],
   "source": [
    "# ─── Evaluate on Test Set ───────────────────────────────────────────────────────\n",
    "model.eval()\n",
    "correct = 0\n",
    "total   = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total   += labels.size(0)\n",
    "\n",
    "test_acc = 100. * correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pAt3ys7p8D1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPPg52wjAei+1sAKDJvZhTL",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
